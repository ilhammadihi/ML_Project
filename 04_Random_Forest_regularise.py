"""
Heart Disease Prediction - Random Forest R√âGULARIS√â
===================================================
Version avec contraintes pour √©viter l'overfitting
"""

import pandas as pd
import numpy as np
import joblib
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score, GridSearchCV
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    classification_report, confusion_matrix, roc_auc_score
)
import matplotlib.pyplot as plt
import seaborn as sns
import os

os.makedirs('images', exist_ok=True)
os.makedirs('models', exist_ok=True)

print("=" * 60)
print("üå≤ RANDOM FOREST - VERSION R√âGULARIS√âE")
print("=" * 60)

# ====================================
# 1. CHARGEMENT DES DONN√âES
# ====================================

print("\nüì• Chargement des donn√©es...")
X_train = pd.read_csv('data/X_train.csv')
X_test = pd.read_csv('data/X_test.csv')
y_train = pd.read_csv('data/y_train.csv').values.ravel()
y_test = pd.read_csv('data/y_test.csv').values.ravel()

print(f"‚úÖ Train : {X_train.shape}")
print(f"‚úÖ Test  : {X_test.shape}")

# ====================================
# 2. ENTRA√éNEMENT AVEC R√âGULARISATION
# ====================================

print("\n‚è≥ Entra√Ænement avec contraintes de r√©gularisation...")

# Param√®tres CONTRAINTS pour √©viter overfitting
model_regularized = RandomForestClassifier(
    n_estimators=50,              # Moins d'arbres (vs 100)
    max_depth=5,                  # Limite la profondeur ‚ö†Ô∏è CL√â
    min_samples_split=10,         # Min √©chantillons pour splitter (vs 2)
    min_samples_leaf=5,           # Min √©chantillons par feuille (vs 1)
    max_features='sqrt',          # Moins de features par arbre
    random_state=42,
    n_jobs=-1
)

print("\nüìä Param√®tres R√âGULARIS√âS :")
print(f"   - n_estimators      : {model_regularized.n_estimators} (r√©duit)")
print(f"   - max_depth         : {model_regularized.max_depth} (limit√©)")
print(f"   - min_samples_split : {model_regularized.min_samples_split} (augment√©)")
print(f"   - min_samples_leaf  : {model_regularized.min_samples_leaf} (augment√©)")
print(f"   - max_features      : {model_regularized.max_features}")

model_regularized.fit(X_train, y_train)
print("‚úÖ Entra√Ænement termin√©")

# ====================================
# 3. COMPARAISON : AVANT vs APR√àS
# ====================================

print("\n" + "=" * 60)
print("üìä COMPARAISON : MOD√àLE ORIGINAL VS R√âGULARIS√â")
print("=" * 60)

# Charge le mod√®le original (si existe)
try:
    model_original = joblib.load('models/random_forest.pkl')
    
    # Pr√©dictions original
    y_train_pred_orig = model_original.predict(X_train)
    y_test_pred_orig = model_original.predict(X_test)
    
    train_acc_orig = accuracy_score(y_train, y_train_pred_orig)
    test_acc_orig = accuracy_score(y_test, y_test_pred_orig)
    
    print("\nüå≤ MOD√àLE ORIGINAL (Sans contraintes) :")
    print(f"   Train Accuracy : {train_acc_orig:.4f} ({train_acc_orig*100:.2f}%)")
    print(f"   Test Accuracy  : {test_acc_orig:.4f} ({test_acc_orig*100:.2f}%)")
    print(f"   Diff√©rence     : {(train_acc_orig - test_acc_orig):.4f}")
    
    if test_acc_orig >= 0.95:
        print("   ‚ö†Ô∏è  Performance suspicieuse (>=95%)")

except:
    print("\n‚ö†Ô∏è  Mod√®le original non trouv√©")
    model_original = None

# Pr√©dictions r√©gularis√©
y_train_pred_reg = model_regularized.predict(X_train)
y_test_pred_reg = model_regularized.predict(X_test)
y_test_proba_reg = model_regularized.predict_proba(X_test)[:, 1]

train_acc_reg = accuracy_score(y_train, y_train_pred_reg)
test_acc_reg = accuracy_score(y_test, y_test_pred_reg)

print("\nüå≤ MOD√àLE R√âGULARIS√â (Avec contraintes) :")
print(f"   Train Accuracy : {train_acc_reg:.4f} ({train_acc_reg*100:.2f}%)")
print(f"   Test Accuracy  : {test_acc_reg:.4f} ({test_acc_reg*100:.2f}%)")
print(f"   Diff√©rence     : {(train_acc_reg - test_acc_reg):.4f}")

if train_acc_reg - test_acc_reg < 0.1:
    print("   ‚úÖ Pas d'overfitting significatif")
else:
    print("   ‚ö†Ô∏è  Overfitting d√©tect√©")

# ====================================
# 4. VALIDATION CROIS√âE
# ====================================

print("\n" + "=" * 60)
print("üîÑ VALIDATION CROIS√âE (Plus Fiable)")
print("=" * 60)

# Combine train + test
X_full = pd.concat([X_train, X_test])
y_full = np.concatenate([y_train, y_test])

print("\n‚è≥ Cross-validation 5-fold...")
cv_scores = cross_val_score(model_regularized, X_full, y_full, 
                            cv=5, scoring='accuracy')

print(f"\nüìä Scores par fold :")
for i, score in enumerate(cv_scores, 1):
    print(f"   Fold {i} : {score:.4f} ({score*100:.2f}%)")

mean_cv = cv_scores.mean()
std_cv = cv_scores.std()

print(f"\nüìà Statistiques CV :")
print(f"   Moyenne    : {mean_cv:.4f} ({mean_cv*100:.2f}%)")
print(f"   √âcart-type : {std_cv:.4f}")
print(f"   Min        : {cv_scores.min():.4f}")
print(f"   Max        : {cv_scores.max():.4f}")

print("\nüí° Le score CV est plus repr√©sentatif que le test accuracy !")

# ====================================
# 5. M√âTRIQUES D√âTAILL√âES
# ====================================

print("\n" + "=" * 60)
print("üìä M√âTRIQUES D√âTAILL√âES")
print("=" * 60)

accuracy = accuracy_score(y_test, y_test_pred_reg)
precision = precision_score(y_test, y_test_pred_reg)
recall = recall_score(y_test, y_test_pred_reg)
f1 = f1_score(y_test, y_test_pred_reg)
roc_auc = roc_auc_score(y_test, y_test_proba_reg)

print(f"\nüìà Performances sur Test Set :")
print(f"   Accuracy  : {accuracy:.4f} ({accuracy*100:.2f}%)")
print(f"   Precision : {precision:.4f} ({precision*100:.2f}%)")
print(f"   Recall    : {recall:.4f} ({recall*100:.2f}%)")
print(f"   F1-Score  : {f1:.4f} ({f1*100:.2f}%)")
print(f"   ROC-AUC   : {roc_auc:.4f}")

print("\nüìã Rapport de Classification :")
print(classification_report(y_test, y_test_pred_reg, 
                           target_names=['Sain', 'Malade']))

# ====================================
# 6. MATRICE DE CONFUSION
# ====================================

cm = confusion_matrix(y_test, y_test_pred_reg)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',
            xticklabels=['Sain', 'Malade'],
            yticklabels=['Sain', 'Malade'],
            cbar_kws={'label': 'Nombre'})

plt.title('Matrice de Confusion - Random Forest R√©gularis√©', 
          fontsize=14, fontweight='bold')
plt.ylabel('Vraie Classe', fontsize=12)
plt.xlabel('Classe Pr√©dite', fontsize=12)

tn, fp, fn, tp = cm.ravel()
plt.text(0.5, -0.15, f'TN={tn} | FP={fp} | FN={fn} | TP={tp}', 
         ha='center', transform=plt.gca().transAxes, fontsize=10)

plt.tight_layout()
plt.savefig('images/confusion_matrix_rf_reg.png', dpi=300, bbox_inches='tight')
plt.show()

print("‚úÖ Matrice sauvegard√©e : images/confusion_matrix_rf_reg.png")

print(f"\nüîç Erreurs commises : {fp + fn} / {len(y_test)}")
print(f"   False Positives : {fp}")
print(f"   False Negatives : {fn}")

# ====================================
# 7. FEATURE IMPORTANCE
# ====================================

print("\nüî• Feature Importance :")
importances = pd.DataFrame({
    'Feature': X_train.columns,
    'Importance': model_regularized.feature_importances_
}).sort_values('Importance', ascending=False)

for i, row in importances.head(5).iterrows():
    print(f"   {i+1}. {row['Feature']:15s} : {row['Importance']:.4f}")

plt.figure(figsize=(10, 6))
plt.barh(importances['Feature'], importances['Importance'], 
         color=plt.cm.viridis(np.linspace(0, 1, len(importances))))
plt.xlabel('Importance')
plt.title('Feature Importance - Random Forest R√©gularis√©', fontweight='bold')
plt.tight_layout()
plt.savefig('images/feature_importance_rf_reg.png', dpi=300, bbox_inches='tight')
plt.show()

print("‚úÖ Feature importance sauvegard√©e : images/feature_importance_rf_reg.png")

# ====================================
# 8. SAUVEGARDE
# ====================================

print("\nüíæ Sauvegarde du mod√®le r√©gularis√©...")
joblib.dump(model_regularized, 'models/random_forest_regularized.pkl')
print("‚úÖ Mod√®le sauvegard√© : models/random_forest_regularized.pkl")

# Sauvegarde les m√©triques
metrics = {
    'Model': 'Random Forest Regularized',
    'Test_Accuracy': accuracy,
    'CV_Mean': mean_cv,
    'CV_Std': std_cv,
    'Precision': precision,
    'Recall': recall,
    'F1-Score': f1,
    'ROC-AUC': roc_auc,
    'Train_Accuracy': train_acc_reg,
    'Overfitting': train_acc_reg - test_acc_reg
}

pd.DataFrame([metrics]).to_csv('models/rf_regularized_metrics.csv', index=False)
print("‚úÖ M√©triques sauvegard√©es : models/rf_regularized_metrics.csv")

# ====================================
# R√âSUM√â & RECOMMANDATIONS
# ====================================

print("\n" + "=" * 60)
print("üí° R√âSUM√â & RECOMMANDATIONS")
print("=" * 60)

print(f"\nüìä SCORES √Ä UTILISER DANS TON PROJET :")
print(f"   Test Accuracy       : {accuracy*100:.2f}%")
print(f"   CV Accuracy (5-fold): {mean_cv*100:.2f}% ¬± {std_cv*100:.2f}%")
print(f"   ROC-AUC             : {roc_auc:.4f}")

print("\nüéØ QUEL SCORE PR√âSENTER ?")
if mean_cv < 0.95:
    print("   ‚úÖ Utilise le score CV (plus cr√©dible)")
    print(f"   ‚Üí \"Random Forest avec CV : {mean_cv*100:.2f}%\"")
else:
    print("   ‚ö†Ô∏è  M√™me le CV est tr√®s √©lev√©")
    print("   ‚Üí Mentionne que c'est un dataset simple/petit")

print("\nüí¨ DANS TA PR√âSENTATION, DIS :")
print("   1. 'Dataset petit (303 patients) ‚Üí performances √©lev√©es'")
print("   2. 'Validation crois√©e utilis√©e pour √©viter surestimation'")
print("   3. 'R√©gularisation appliqu√©e (max_depth=5)'")
print("   4. 'Future: Valider sur donn√©es externes'")

print("\n‚úÖ Random Forest R√©gularis√© termin√© !")