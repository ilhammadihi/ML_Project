import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import joblib
import os

print("=" * 60)
print("ðŸ”§ PREPROCESSING")
print("=" * 60)

# 1. Charge les donnÃ©es
df = pd.read_csv('data/heart.csv')
print(f"\nâœ… Dataset chargÃ© : {df.shape}")

# 2. SÃ©pare X et y
X = df.drop('target', axis=1)
y = df['target']

print(f"\nâœ… Features (X) : {X.shape}")
print(f"âœ… Target (y) : {y.shape}")

# 3. Train-test split
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2, 
    random_state=42,
    stratify=y
)

print(f"\nðŸ“Š Train : {X_train.shape[0]} Ã©chantillons (80%)")
print(f"ðŸ“Š Test  : {X_test.shape[0]} Ã©chantillons (20%)")

# 4. Feature Scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Reconvertit en DataFrame
X_train_scaled = pd.DataFrame(X_train_scaled, columns=X.columns, index=X_train.index)
X_test_scaled = pd.DataFrame(X_test_scaled, columns=X.columns, index=X_test.index)

print("\nâœ… Feature scaling appliquÃ©")

# 5. Sauvegarde
os.makedirs('data', exist_ok=True)
os.makedirs('models', exist_ok=True)

X_train_scaled.to_csv('data/X_train.csv', index=False)
X_test_scaled.to_csv('data/X_test.csv', index=False)
pd.DataFrame(y_train).to_csv('data/y_train.csv', index=False)
pd.DataFrame(y_test).to_csv('data/y_test.csv', index=False)
joblib.dump(scaler, 'models/scaler.pkl')

print("\nðŸ’¾ Fichiers sauvegardÃ©s :")
print("   - data/X_train.csv")
print("   - data/X_test.csv")
print("   - data/y_train.csv")
print("   - data/y_test.csv")
print("   - models/scaler.pkl")

print("\nâœ… Preprocessing terminÃ© !")